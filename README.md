Face Emotion Detection
ğŸ“Œ Authors: Sayali Lokhande, Bhuvana Ravikumar, Anish Kataria
ğŸ“„ Report: MLD_Final_Report.pdf

ğŸ“Œ Overview
This project explores techniques to improve face emotion detection accuracy using ResNet-18 and Tiny-ViT models.
Face emotion detection is crucial in mental health analysis, human-computer interaction, and surveillance.
Our goal is to evaluate different optimization strategies and improve model performance.

ğŸ“Œ Dataset
FER2013 Dataset (Kaggle Link)
Contains 48x48 grayscale facial images categorized into 7 emotions:
Anger, Disgust, Fear, Happiness, Sadness, Surprise, Neutral.
28,709 training images & 3,589 testing images.
ğŸ“Œ Models Used
ğŸ”¹ ResNet-18 (PyTorch Model)
ğŸ”¹ Tiny-ViT (ViT-B/16) (Hugging Face Model)

ğŸ“Œ Optimization Techniques
We applied five different optimization techniques for improving accuracy:
1ï¸âƒ£ Learning Rate Scheduling: StepLR reduces learning rate at fixed intervals.
2ï¸âƒ£ Regularization: Dropout & L2 weight decay to prevent overfitting.
3ï¸âƒ£ Data Augmentation: Random flipping, rotation, color jittering for improved generalization.
4ï¸âƒ£ Increased Training Epochs: Extended training up to 50 epochs.
5ï¸âƒ£ Hyperparameter Tuning: Adjusting optimizers, batch sizes, and learning rates.

ğŸ“Œ Results
ğŸ“Œ ResNet-18 performed better with data augmentation and hyperparameter tuning, while Tiny-ViT performed best with regularization techniques.
